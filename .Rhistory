# Simulation begins
sims <- pbreplicate(nsim, sim_fn())
# Make sure the multiplier for unif CI is no smaller than that for ptwise CI
calpha_lb <- sims[1, "calpha_lb", ]
expect_true(all(calpha_lb >= qnorm(1-alpha/2)))
calpha_ub <- sims[1, "calpha_ub", ]
expect_true(all(calpha_ub >= qnorm(1-alpha/2)))
# Check uniform coverage (%) is okay
cvg <- coverage(sims[, "ci_lo", ], sims[, "ci_hi", ], psil, psiu)
expect_true(abs(cvg - 100 * (1 - alpha)) <= 5)
})
c(1, 3) %*% t(c(1, 3))
c(1, 2, 3) %*% t(c(1, 2, 3))
diag(c(1, 2, 3)) %*% t(diag(c(1, 2, 3)))
c(0, 1, 2, 3) %*% t(c(0, 1, 2, 3))
mat <- matrix(c(1,2,3,4), byrow = TRUE, ncol = 2)
hmat <- diag(c(1, 2))
hmat %*%mat %*%hmat
mat
mat <- matrix(c(1,2,2,3), byrow = TRUE, ncol = 2)
hmat <- diag(c(1, 2))
hmat %*%mat %*%hmat
mat
mat <- matrix(c(1,2,2,3,4,3,4,5), byrow = TRUE, ncol = 2)
mat
mat <- matrix(c(1,2,2,3,4,3,4,5), byrow = TRUE, ncol = 3)
mat <- matrix(c(1,2,3,2,3,4,3,4,5), byrow = TRUE, ncol = 3)
mat
hmat <- diag(c(1, 2, 3))
hmat %*%mat %*%hmat
gamma.inv <- matrix(c(1, 0, 0, 1/6), byrow = TRUE, ncol = 2)
gamma.inv
dd <- matrix(c(0, 1/6), ncol = 1)
dd
psi <- matrix(c(2/3, 0, 0, 1/15), byrow = TRUE, ncol = 2)
3 * gamma.inv %*% psi %*% gamma.inv
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv evec
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
evec <- c(1, 0)
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
num
t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
gamma.inv %*% psi %*% gamma.inv
t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
den <- 2 * t(evec) %*% gamma.inv %*% dd
den
gamma.inv %*% dd
evec <- c(0, 1)
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
den <- 2 * t(evec) %*% gamma.inv %*% dd
den
num / den
(num / den)^{1/5}
gamma.inv <- solve(matrix(c(1, 0, 0, 1/6), byrow = TRUE, ncol = 2))
gamma.inv
dd <- matrix(c(0, 1/6), ncol = 1)
psi <- matrix(c(2/3, 0, 0, 1/15), byrow = TRUE, ncol = 2)
evec <- c(0, 1)
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
den <- 2 * t(evec) %*% gamma.inv %*% dd
(num / den)^{1/5}
gamma.inv <- solve(matrix(c(1/2, 1/6, 1/6, 1/12), byrow = TRUE, ncol = 2))
dd <- matrix(c(1/6, 1/12), ncol = 1)
psi <- matrix(c(2, 1/12, 1/12, 1/30), byrow = TRUE, ncol = 2)
evec <- c(0, 1)
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
den <- 2 * t(evec) %*% gamma.inv %*% dd
(num / den)^{1/5}
evec <- c(1, 0)
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
den <- 2 * t(evec) %*% gamma.inv %*% dd
(num / den)^{1/5}
den
gamma.inv %*% psi %*% gamma.inv
dd
gamma.inv
gamma.inv %*% dd
psi <- matrix(c(1/3, 1/12, 1/12, 1/30), byrow = TRUE, ncol = 2)
evec <- c(1, 0)
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
den <- 2 * t(evec) %*% gamma.inv %*% dd
(num / den)^{1/5}
gamma.inv <- solve(matrix(c(1/2, 1/6, 1/6, 1/12), byrow = TRUE, ncol = 2))
dd <- matrix(c(1/6, 1/12), ncol = 1)
psi <- matrix(c(1/3, 1/12, 1/12, 1/30), byrow = TRUE, ncol = 2)
evec <- c(1, 0)
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
gamma.inv %*% dd
gamma.inv <- solve(matrix(c(1/2, 1/6, 1/6, 1/12), byrow = TRUE, ncol = 2))
dd <- matrix(c(1/12, 1/20), ncol = 1)
psi <- matrix(c(1/3, 1/12, 1/12, 1/30), byrow = TRUE, ncol = 2)
evec <- c(1, 0)
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
den <- 2 * t(evec) %*% gamma.inv %*% dd
(num / den)^{1/5}
num
den
gamma.inv
C1 <- 0.25 * ((nu2^2 - nu1*nu3) / (nu2 * nu0 - nu1^2) )^2
nu0 <- 1/2
nu1 <- 1/6
nu2 <- 1/12
nu3 <- 1/20
pi0 <- 1/3
pi1 <- 1/12
pi2 <- 1/30
C1 <- 0.25 * ((nu2^2 - nu1*nu3) / (nu2 * nu0 - nu1^2) )^2
C1
((nu2^2 - nu1*nu3) / (nu2 * nu0 - nu1^2) )^2
C2 <- (nu2^2*pi0 - 2*nu1*nu2*pi1 + nu1^2*pi2) / ((nu2 * nu0 - nu1^2)^2)
C2
C2 / (4 * C1)
( C2 / (4 * C1) ) ^(1/5)
gamma.inv %*% psi %*% gamma.inv
t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
(nu2^2*pi0 - 2*nu1*nu2*pi1 + nu1^2*pi2) / ((nu2 * nu0 - nu1^2)^2)
((nu2^2 - nu1*nu3) / (nu2 * nu0 - nu1^2) )^2
(nu2^2*pi0 - 2*nu1*nu2*pi1 + nu1^2*pi2) / ((nu2 * nu0 - nu1^2)^2)
t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
t(evec) %*% gamma.inv %*% dd
(nu2^2*pi0 - 2*nu1*nu2*pi1 + nu1^2*pi2) / ((nu2 * nu0 - nu1^2)^2)
((nu2^2 - nu1*nu3) / (nu2 * nu0 - nu1^2) )^2
((nu2^2 - nu1*nu3) / (nu2 * nu0 - nu1^2) )^2
t(evec) %*% gamma.inv %*% dd
dd
(nu2^2 - nu1*nu3)
(nu2^2 - nu1*nu3) / (nu2 * nu0 - nu1^2)
den <- 2 * t(evec) %*% gamma.inv %*% dd %*% t(dd) %*% gamma.inv %*% evec
den
evec <- c(0, 1)
num <- 3 * t(evec) %*% gamma.inv %*% psi %*% gamma.inv %*% evec
den <- 2 * t(evec) %*% gamma.inv %*% dd %*% t(dd) %*% gamma.inv %*% evec
(num / den)^{1/5}
t(evec) %*% gamma.inv %*% dd
0.64 * 2
den
(num / den)
n <- 1000
x <- runif(n)
pa.x <- pnorm(x)
library(SuperLearner)
l <- matrix(runif(2* n), ncol = 2, nrow = n)
a <- rbinom(n, 1, pnorm(l[, 1] + l[, 2]))
a <- pnorm(l[, 1] + l[, 2])
a.min <- min(a)
a.min
a.max <- max(a)
a.max
a.vals <- seq(a.min,a.max,length.out=100)
la.new <- rbind(cbind(l,a), cbind( l[rep(1:n,length(a.vals)),],a=rep(a.vals,rep(n,length(a.vals))) ))
l.new <- la.new[,-dim(la.new)[2]]
sl.lib <- c("SL.earth","SL.gam","SL.gbm","SL.glm","SL.glmnet")
pimod <- SuperLearner(Y=a, X=l, SL.library=sl.lib, newX=l.new)
sl.lib <- c("SL.glm")
pimod <- SuperLearner(Y=a, X=l, SL.library=sl.lib, newX=l.new)
a.min <- min(a)
a.max <- max(a)
a.vals <- seq(a.min,a.max,length.out=100)
la.new <- rbind(cbind(l,a), cbind( l[rep(1:n,length(a.vals)),],a=rep(a.vals,rep(n,length(a.vals))) ))
l.new <- la.new[,-dim(la.new)[2]]
l.new
colnames(l) <- c("X1", "X2")
a <- pnorm(l[, 1] + l[, 2])
a.min <- min(a)
a.max <- max(a)
a.vals <- seq(a.min,a.max,length.out=100)
la.new <- rbind(cbind(l,a), cbind( l[rep(1:n,length(a.vals)),],a=rep(a.vals,rep(n,length(a.vals))) ))
l.new <- la.new[,-dim(la.new)[2]]
sl.lib <- c("SL.glm")
pimod <- SuperLearner(Y=a, X=l, SL.library=sl.lib, newX=l.new)
library(SuperLearner)
n <- 1000
l <- as.data.frame(matrix(runif(2* n), ncol = 2, nrow = n))
colnames(l) <- c("X1", "X2")
a <- pnorm(l[, 1] + l[, 2])
a.min <- min(a)
a.max <- max(a)
a.vals <- seq(a.min,a.max,length.out=100)
la.new <- rbind(cbind(l,a), cbind( l[rep(1:n,length(a.vals)),],a=rep(a.vals,rep(n,length(a.vals))) ))
l.new <- la.new[,-dim(la.new)[2]]
sl.lib <- c("SL.glm")
pimod <- SuperLearner(Y=a, X=l, SL.library=sl.lib, newX=l.new)
pimod.vals <- pimod$SL.predict
sq.res <- (a-pimod.vals)^2
pi2mod <- SuperLearner(Y=sq.res,X=l, SL.library=sl.lib, newX=l.new)
sq.res
pi2mod <- SuperLearner(Y=sq.res,X=l, SL.library=sl.lib, newX=l.new)
dim(sq.res)
sq.res <- as.vector((a-pimod.vals)^2)
pi2mod <- SuperLearner(Y=sq.res,X=l, SL.library=sl.lib, newX=l.new)
dim(sq.res)
library(SuperLearner)
n <- 1000
l <- as.data.frame(matrix(runif(2* n), ncol = 2, nrow = n))
colnames(l) <- c("X1", "X2")
a <- pnorm(l[, 1] + l[, 2])
a.min <- min(a)
a.max <- max(a)
a.vals <- seq(a.min,a.max,length.out=100)
la.new <- rbind(cbind(l,a), cbind( l[rep(1:n,length(a.vals)),],a=rep(a.vals,rep(n,length(a.vals))) ))
l.new <- la.new[,-dim(la.new)[2]]
dim(l.new)
sq.res <- as.vector((a-pimod.vals[1:n])^2)
pi2mod <- SuperLearner(Y=sq.res,X=l, SL.library=sl.lib, newX=l.new)
pi2mod.vals <- pi2mod$SL.predict
mumod <- SuperLearner(Y=y, X=cbind(l,a), SL.library=sl.lib, newX=la.new,family=binomial)
y <- rbinom(n, 1, 0.5)
mumod <- SuperLearner(Y=y, X=cbind(l,a), SL.library=sl.lib, newX=la.new,family=binomial)
muhat.vals <- mumod$SL.predict
approx.fn <- function(x,y,z){ predict(smooth.spline(x,y),x=x2)$y }
a.std <- (la.new$a-pimod.vals)/sqrt(pi2mod.vals)
pihat.vals <- approx.fn(density(a.std[1:n])$x, density(a.std[1:n])$y,a.std)
approx.fn <- function(x,y,z){ predict(smooth.spline(x,y), x=z)$y }
a.std <- (la.new$a-pimod.vals)/sqrt(pi2mod.vals)
pihat.vals <- approx.fn(density(a.std[1:n])$x, density(a.std[1:n])$y,a.std)
pihat <- pihat.vals[1:n]
pihat.mat <- matrix(pihat.vals[-(1:n)], nrow=n,ncol=length(a.vals))
varpihat <- approx.fn(a.vals, apply(pihat.mat,2,mean), a)
varpihat.mat <- matrix(rep(apply(pihat.mat,2,mean),n), byrow=T,nrow=n)
muhat <- muhat.vals[1:n]
muhat.mat <- matrix(muhat.vals[-(1:n)], nrow=n,ncol=length(a.vals))
mhat <- approx.fn(a.vals, apply(muhat.mat,2,mean), a)
mhat.mat <- matrix( rep(apply(muhat.mat,2,mean),n), byrow=T,nrow=n)
pihat
dnorm(1, mean = aval, sd = sqrt(tvals))
tval <- 0.002
aval <- 2
dnorm(1, mean = aval, sd = sqrt(tvals))
dnorm(1, mean = aval, sd = sqrt(tval))
dnorm(2, mean = aval, sd = sqrt(tval))
tval <- 0.00002
aval <- 2
dnorm(2, mean = aval, sd = sqrt(tval))
tval <- 1/1000000
aval <- 2
dnorm(2, mean = aval, sd = sqrt(tval))
tval <- 1/100000000000
aval <- 2
dnorm(2, mean = aval, sd = sqrt(tval))
dnorm(2 - tval, mean = aval, sd = sqrt(tval))
dnorm(1.9, mean = aval, sd = sqrt(tval))
dnorm(1.999, mean = aval, sd = sqrt(tval))
dnorm(1.9999999, mean = aval, sd = sqrt(tval))
dnorm(1.99999, mean = aval, sd = sqrt(tval))
dnorm(1.9999, mean = aval, sd = sqrt(tval))
tval <- 1e-17
aval <- 2
dnorm(1.9999, mean = aval, sd = sqrt(tval))
dnorm(1.999999, mean = aval, sd = sqrt(tval))
dnorm(1.9999999999, mean = aval, sd = sqrt(tval))
dnorm(1.99999999, mean = aval, sd = sqrt(tval))
dnorm(1.9999999, mean = aval, sd = sqrt(tval))
install.packages("fdrtool")
library(fdrtool)
qhalfnorm(0.95, 1)
qhalfnorm(0.95)
?rhalfnorm
library(foreign)
library(rdrobust)
library(rddensity)
library(dplyr)
rm(list=ls())
setwd("~/Dropbox/RDD NIH Grant/projects/threshold_opt/data")
data <- read.dta("mort_out.dta")
z <- seq(-1, 1, 0.001)
library(ggplot2)
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("utils.R")
source("plot_theme.R")
mean_1 <- function(z) {
return(1 + cos(z) + sin(z))
}
mean_0 <- function(z) {
return(1 + cos(z) + sin(z))
}
z <- seq(-1, 1, 0.001)
##########################################################
## Analyze data of Connors et al (1996) as in Section 5 ##
##########################################################
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(devtools)
library(varhandle)
Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS=TRUE)
# devtools::install_github("matteobonvini/sensitivitypuc")
devtools::install("C:/Users/matte/Desktop/sensitivitypuc")
library(sensitivitypuc)
set.seed(1000)
data_url <- "http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/rhc.csv"
dat <- read.csv(data_url, header = TRUE)
covariates <- c("age", "sex", "race", "edu", "income",
"ninsclas", "cat1", "cat2",
"resp", "card", "neuro", "gastr", "renal", "meta",
"hema", "seps", "trauma", "ortho",
"adld3p", "das2d3pc", "dnr1", "ca",  "aps1", "scoma1",
"wtkilo1", "temp1", "meanbp1", "resp1", "hrt1", "pafi1",
"paco21", "ph1", "wblc1", "hema1", "sod1", "pot1", "crea1",
"bili1", "alb1", "urin1",
"cardiohx", "chfhx", "dementhx",
"psychhx", "chrpulhx", "renalhx", "liverhx", "gibledhx",
"malighx", "immunhx", "transhx", "amihx")
# Exclude covariates with missing values
x <- dat[, covariates]
miss_covs <- covariates[apply(x, 2, function(x) sum(is.na(x)) > 0)]
print(paste("Discarding covariates:", paste(miss_covs, collapse = ", ")))
x <- x[, !covariates %in% miss_covs]
# Fix factors or otherwise SuperLearner complains
newdf <- x
for(i in 1:ncol(x)) {
if(class(x[, i])=="factor") {
new <- to.dummy(x[, i], colnames(x)[i])
newdf <- newdf[, !colnames(newdf)%in%colnames(x)[i]]
newdf <- cbind(newdf, new[, -1, drop=FALSE])
}
}
x <- newdf
rm(newdf)
rm(new)
# Avoid SuperLearner conflicts due to variable names
colnames(x) <- paste("x", 1:ncol(x), sep = "")
# A = 1 means patient underwent RHC
a <- ifelse(dat$swang1 == "No RHC", 0, 1)
# Y = 1 means survival at day 30
y <- ifelse(dat$dth30 == "No", 1, 0)
# Select values for prop of unmeasured confounding at which evaluate bounds
eps_seq <- seq(0, 0.6, 0.0001)
delta_seq <- c(0.25, 0.50, 0.75, 1)
# Select model, "x" = S \ind (Y, A) | X, "xa" = S \ind Y | (X, A)
model <- c("x", "xa")
# Select SuperLearner Library
sl.lib <- c("SL.mean", "SL.speedlm", "SL.speedglm", "SL.gam",
"SL.ranger", "SL.polymars", "SL.svm")
# Estimate Regression functions once for both model "x" and model "xa"
# There is a "non-list contrasts argument ignored" warning from SL gam library
# coming from model.matrix, which I think can be ignored.
nuis_fns <- do_crossfit(y = y, a = a, x = x, ymin = 0, ymax = 1, nsplits = 5,
outfam = binomial(), treatfam = binomial(),
sl.lib = sl.lib, do_parallel = TRUE, ncluster = 3,
show_progress = TRUE)
##########################################################
## Analyze data of Connors et al (1996) as in Section 5 ##
##########################################################
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(devtools)
library(varhandle)
Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS=TRUE)
# devtools::install_github("matteobonvini/sensitivitypuc")
devtools::install("C:/Users/matte/Desktop/sensitivitypuc")
##########################################################
## Analyze data of Connors et al (1996) as in Section 5 ##
##########################################################
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(devtools)
library(varhandle)
Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS=TRUE)
# devtools::install_github("matteobonvini/sensitivitypuc")
devtools::install("C:/Users/matte/Desktop/sensitivitypuc")
library(sensitivitypuc)
set.seed(1000)
data_url <- "http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/rhc.csv"
dat <- read.csv(data_url, header = TRUE)
covariates <- c("age", "sex", "race", "edu", "income",
"ninsclas", "cat1", "cat2",
"resp", "card", "neuro", "gastr", "renal", "meta",
"hema", "seps", "trauma", "ortho",
"adld3p", "das2d3pc", "dnr1", "ca",  "aps1", "scoma1",
"wtkilo1", "temp1", "meanbp1", "resp1", "hrt1", "pafi1",
"paco21", "ph1", "wblc1", "hema1", "sod1", "pot1", "crea1",
"bili1", "alb1", "urin1",
"cardiohx", "chfhx", "dementhx",
"psychhx", "chrpulhx", "renalhx", "liverhx", "gibledhx",
"malighx", "immunhx", "transhx", "amihx")
# Exclude covariates with missing values
x <- dat[, covariates]
miss_covs <- covariates[apply(x, 2, function(x) sum(is.na(x)) > 0)]
print(paste("Discarding covariates:", paste(miss_covs, collapse = ", ")))
x <- x[, !covariates %in% miss_covs]
# Fix factors or otherwise SuperLearner complains
newdf <- x
for(i in 1:ncol(x)) {
if(class(x[, i])=="factor") {
new <- to.dummy(x[, i], colnames(x)[i])
newdf <- newdf[, !colnames(newdf)%in%colnames(x)[i]]
newdf <- cbind(newdf, new[, -1, drop=FALSE])
}
}
x <- newdf
rm(newdf)
rm(new)
# Avoid SuperLearner conflicts due to variable names
colnames(x) <- paste("x", 1:ncol(x), sep = "")
# A = 1 means patient underwent RHC
a <- ifelse(dat$swang1 == "No RHC", 0, 1)
# Y = 1 means survival at day 30
y <- ifelse(dat$dth30 == "No", 1, 0)
# Select values for prop of unmeasured confounding at which evaluate bounds
eps_seq <- seq(0, 0.6, 0.0001)
delta_seq <- c(0.25, 0.50, 0.75, 1)
# Select model, "x" = S \ind (Y, A) | X, "xa" = S \ind Y | (X, A)
model <- c("x", "xa")
# Select SuperLearner Library
sl.lib <- c("SL.mean", "SL.speedlm", "SL.speedglm", "SL.gam",
"SL.ranger", "SL.polymars", "SL.svm")
# Estimate Regression functions once for both model "x" and model "xa"
# There is a "non-list contrasts argument ignored" warning from SL gam library
# coming from model.matrix, which I think can be ignored.
nuis_fns <- do_crossfit(y = y, a = a, x = x, ymin = 0, ymax = 1, nsplits = 5,
outfam = binomial(), treatfam = binomial(),
sl.lib = sl.lib, do_parallel = TRUE, ncluster = 3,
show_progress = TRUE)
##########################################################
## Analyze data of Connors et al (1996) as in Section 5 ##
##########################################################
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(devtools)
library(varhandle)
Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS=TRUE)
# devtools::install_github("matteobonvini/sensitivitypuc")
devtools::install("C:/Users/matte/Desktop/sensitivitypuc")
library(sensitivitypuc)
set.seed(1000)
data_url <- "http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/rhc.csv"
dat <- read.csv(data_url, header = TRUE)
covariates <- c("age", "sex", "race", "edu", "income",
"ninsclas", "cat1", "cat2",
"resp", "card", "neuro", "gastr", "renal", "meta",
"hema", "seps", "trauma", "ortho",
"adld3p", "das2d3pc", "dnr1", "ca",  "aps1", "scoma1",
"wtkilo1", "temp1", "meanbp1", "resp1", "hrt1", "pafi1",
"paco21", "ph1", "wblc1", "hema1", "sod1", "pot1", "crea1",
"bili1", "alb1", "urin1",
"cardiohx", "chfhx", "dementhx",
"psychhx", "chrpulhx", "renalhx", "liverhx", "gibledhx",
"malighx", "immunhx", "transhx", "amihx")
# Exclude covariates with missing values
x <- dat[, covariates]
miss_covs <- covariates[apply(x, 2, function(x) sum(is.na(x)) > 0)]
print(paste("Discarding covariates:", paste(miss_covs, collapse = ", ")))
x <- x[, !covariates %in% miss_covs]
# Fix factors or otherwise SuperLearner complains
newdf <- x
for(i in 1:ncol(x)) {
if(class(x[, i])=="factor") {
new <- to.dummy(x[, i], colnames(x)[i])
newdf <- newdf[, !colnames(newdf)%in%colnames(x)[i]]
newdf <- cbind(newdf, new[, -1, drop=FALSE])
}
}
x <- newdf
rm(newdf)
rm(new)
# Avoid SuperLearner conflicts due to variable names
colnames(x) <- paste("x", 1:ncol(x), sep = "")
# A = 1 means patient underwent RHC
a <- ifelse(dat$swang1 == "No RHC", 0, 1)
# Y = 1 means survival at day 30
y <- ifelse(dat$dth30 == "No", 1, 0)
# Select values for prop of unmeasured confounding at which evaluate bounds
eps_seq <- seq(0, 0.6, 0.0001)
delta_seq <- c(0.25, 0.50, 0.75, 1)
# Select model, "x" = S \ind (Y, A) | X, "xa" = S \ind Y | (X, A)
model <- c("x", "xa")
# Select SuperLearner Library
# sl.lib <- c("SL.mean", "SL.speedlm", "SL.speedglm", "SL.gam",
#             "SL.ranger", "SL.polymars", "SL.svm")
sl.lib <- c("SL.mean", "SL.speedlm", "SL.speedglm", "SL.ranger", "SL.polymars", "SL.svm")
# Estimate Regression functions once for both model "x" and model "xa"
# There is a "non-list contrasts argument ignored" warning from SL gam library
# coming from model.matrix, which I think can be ignored.
nuis_fns <- do_crossfit(y = y, a = a, x = x, ymin = 0, ymax = 1, nsplits = 5,
outfam = binomial(), treatfam = binomial(),
sl.lib = sl.lib, do_parallel = TRUE, ncluster = 3,
show_progress = TRUE)
##########################################################
## Analyze data of Connors et al (1996) as in Section 5 ##
##########################################################
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(devtools)
library(varhandle)
Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS=TRUE)
# devtools::install_github("matteobonvini/sensitivitypuc")
devtools::install("C:/Users/matte/Desktop/sensitivitypuc")
library(sensitivitypuc)
set.seed(1000)
data_url <- "http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/rhc.csv"
dat <- read.csv(data_url, header = TRUE)
##########################################################
## Analyze data of Connors et al (1996) as in Section 5 ##
##########################################################
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(devtools)
library(varhandle)
Sys.setenv(R_REMOTES_NO_ERRORS_FROM_WARNINGS=TRUE)
# devtools::install_github("matteobonvini/sensitivitypuc")
devtools::install("C:/Users/matte/Desktop/sensitivitypuc")
library(sensitivitypuc)
set.seed(1000)
data_url <- "http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/rhc.csv"
dat <- read.csv(data_url, header = TRUE)
rm(list = ls())
library(devtools)
library(varhandle)
library(sensitivitypuc)
set.seed(1000)
data_url <- "http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/rhc.csv"
dat <- read.csv(data_url, header = TRUE)
